---
title: "Predicting Classifier Performance With A Small Training Set: Applications To Computer-Aided Diagnosis And Prognosis"
author: Basavanhally, A., Doyle, S., Madabhushi, A.
status: Published
type: conference
citation: "Predicting Classifier Performance With A Small Training Set: Applications To Computer-Aided Diagnosis And Prognosis, <em>2010 IEEE 7th International Symposium on Biomedical Imaging (ISBI)</em>, 2010"
comments: no
doi: 10.1109/ISBI.2010.5490373
date: 2010-01-01
publishdate: 2010-01-01
---

Selection of an appropriate classifier for computer-aided diagnosis (CAD) applications has typically been an ad hoc process. It is difficult to know a priori which classifier will yield high accuracies for a specific application, especially when well-annotated data for classifier training is scarce. In this study, we utilize an inverse power-law model of statistical learning to predict classifier performance when only limited amounts of annotated training data is available. The objectives of this study are to (a) predict classifier error in the context of different CAD problems when larger data cohorts become available, and (b) compare classifier performance and trends (both at the sample/patient level and at the pixel level) as additional data is accrued (such as in a clinical trial). In this paper we utilize a power law model to evaluate and compare various classifiers (Support Vector Machine (SVM), C4.5 decision tree, k-nearest neighbor) for four distinct CAD problems. The first two datasets deal with sample/patient-level classification for distinguishing between (1) high from low grade breast cancers and (2) high from low levels of lymphocytic infiltration in breast cancer specimens. The other two datasets are pixel-level classification problems for discriminating cancerous and non-cancerous regions on prostate (3) MRI and (4) histopathology. Our empirical results suggest that, given sufficient training data, SVMs tend to be the best classifiers. This was true for datasets (1), (2), and (3), while the C4.5 decision tree was the best classifier for dataset (4). Our results also suggest that results of classifier comparison made on small data cohorts should not be generalized as holding true when large amounts of data become available.
